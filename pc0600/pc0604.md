## Problem

You need to extract data from a huge XML document using as little memory as possible.

## Solution

Any time you are faced with the problem of incremental data processing, you should think of iterators and generators. Here is a simple function that can be used to incrementally process huge XML files using a very small memory footprint:

```
from xml.etree.ElementTree import iterparse

def parse_and_remove(filename, path):
    path_parts = path.split('/')
    doc = iterparse(filename, ('start', 'end'))
    # Skip the root element
    next(doc)

    tag_stack = []
    elem_stack = []
    for event, elem in doc:
        if event == 'start':
            tag_stack.append(elem.tag)
            elem_stack.append(elem)
        elif event == 'end':
            if tag_stack == path_parts:
                yield elem
                elem_stack[-2].remove(elem)
            try:
                tag_stack.pop()
                elem_stack.pop()
            except IndexError:
                pass
```{{execute}}

To test the function, you now need to find a large XML file to work with. You can often find such files on government and open data websites. For example, you can download [Chicago’s pothole database as XML](http://bit.ly/YQh2Oh). At the time of this writing, the downloaded file consists of more than 100,000 rows of data, which are encoded like this:

    <response>
      <row>
        <row ...>
          <creation\_date>2012-11-18T00:00:00</creation\_date>
          <status>Completed</status>
          <completion\_date>2012-11-18T00:00:00</completion\_date>
          <service\_request\_number>12-01906549</service\_request\_number>
          <type\_of\_service\_request>Pot Hole in Street</type\_of\_service\_request>
          <current\_activity>Final Outcome</current\_activity>
          <most\_recent\_action>CDOT Street Cut ... Outcome</most\_recent\_action>
          <street\_address>4714 S TALMAN AVE</street\_address>
          <zip>60632</zip>
          <x\_coordinate>1159494.68618856</x\_coordinate>
          <y\_coordinate>1873313.83503384</y\_coordinate>
          <ward>14</ward>
          <police\_district>9</police\_district>
          <community\_area>58</community\_area>
          <latitude>41.808090232127896</latitude>
          <longitude>-87.69053684711305</longitude>
          <location latitude="41.808090232127896"
                   longitude="-87.69053684711305" />
        </row>
        <row ...>
          <creation\_date>2012-11-18T00:00:00</creation\_date>
          <status>Completed</status>
          <completion\_date>2012-11-18T00:00:00</completion\_date>
          <service\_request\_number>12-01906695</service\_request\_number>
          <type\_of\_service\_request>Pot Hole in Street</type\_of\_service\_request>
          <current\_activity>Final Outcome</current\_activity>
          <most\_recent\_action>CDOT Street Cut ... Outcome</most\_recent\_action>
          <street\_address>3510 W NORTH AVE</street\_address>
          <zip>60647</zip>
          <x\_coordinate>1152732.14127696</x\_coordinate>
          <y\_coordinate>1910409.38979075</y\_coordinate>
          <ward>26</ward>
          <police\_district>14</police\_district>
          <community\_area>23</community\_area>
          <latitude>41.91002084292946</latitude>
          <longitude>-87.71435952353961</longitude>
          <location latitude="41.91002084292946"
                   longitude="-87.71435952353961" />
        </row>
      </row>
    </response>

Suppose you want to write a script that ranks ZIP codes by the number of pothole reports. To do it, you could write code like this:

```
from xml.etree.ElementTree import parse
from collections import Counter

potholes_by_zip = Counter()

doc = parse('potholes.xml')
for pothole in doc.iterfind('row/row'):
    potholes_by_zip[pothole.findtext('zip')] += 1

for zipcode, num in potholes_by_zip.most_common():
    print(zipcode, num)
```{{execute}}

The only problem with this script is that it reads and parses the entire XML file into memory. On our machine, it takes about 450 MB of memory to run. Using this recipe’s code, the program changes only slightly:

```
from collections import Counter
potholes_by_zip = Counter()

data = parse_and_remove('potholes.xml', 'row/row')
for pothole in data:
    potholes_by_zip[pothole.findtext('zip')] += 1

for zipcode, num in potholes_by_zip.most_common():
    print(zipcode, num)
```{{execute}}

This version of code runs with a memory footprint of only 7 MB—​a huge savings!

## Discussion

This recipe relies on two core features of the `ElementTree` module. First, the `iterparse()` method allows incremental processing of XML documents. To use it, you supply the filename along with an event list consisting of one or more of the following: `start`, `end`, `start-ns`, and `end-ns`. The iterator created by `iterparse()` produces tuples of the form `(event, elem)`, where `event` is one of the listed events and `elem` is the resulting XML element. For example:

```
>>> data = iterparse('potholes.xml',('start','end'))
>>> next(data)
('start', <Element 'response' at 0x100771d60>)
>>> next(data)
('start', <Element 'row' at 0x100771e68>)
>>> next(data)
('start', <Element 'row' at 0x100771fc8>)
>>> next(data)
('start', <Element 'creation_date' at 0x100771f18>)
>>> next(data)
('end', <Element 'creation_date' at 0x100771f18>)
>>> next(data)
('start', <Element 'status' at 0x1006a7f18>)
>>> next(data)
('end', <Element 'status' at 0x1006a7f18>)
>>>
```{{execute}}

`start` events are created when an element is first created but not yet populated with any other data (e.g., child elements). `end` events are created when an element is completed. Although not shown in this recipe, `start-ns` and `end-ns` events are used to handle XML namespace declarations.

In this recipe, the start and end events are used to manage stacks of elements and tags. The stacks represent the current hierarchical structure of the document as it’s being parsed, and are also used to determine if an element matches the requested path given to the `parse_and_remove()` function. If a match is made, `yield` is used to emit it back to the caller.

The following statement after the `yield` is the core feature of `ElementTree` that makes this recipe save memory:

```
elem_stack[-2].remove(elem)
```{{execute}}

This statement causes the previously yielded element to be removed from its parent. Assuming that no references are left to it anywhere else, the element is destroyed and memory reclaimed.

The end effect of the iterative parse and the removal of nodes is a highly efficient incremental sweep over the document. At no point is a complete document tree ever constructed. Yet, it is still possible to write code that processes the XML data in a straightforward manner.

The primary downside to this recipe is its runtime performance. When tested, the version of code that reads the entire document into memory first runs approximately twice as fast as the version that processes it incrementally. However, it requires more than 60 times as much memory. So, if memory use is a greater concern, the incremental version is a big win.