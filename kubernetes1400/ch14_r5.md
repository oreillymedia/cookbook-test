## Problem

You want to create a Kubernetes cluster on AWS.

## Solution

Use [`kubicorn`](https://github.com/kris-nova/kubicorn) to create and manage Kubernetes clusters on AWS. Since `kubicorn` currently doesn’t provide for binary releases, you need to have [Go installed](https://golang.org/dl/) for the following to work.

First, install `kubicorn` and make sure that Go (version 1.8 or later) is available. Here, we’re using a CentOS environment.

$ **go version**
go version go1.8 linux/amd64

$ **yum group install "Development Tools" \\
  yum install ncurses-devel**

$ **go get github.com/kris-nova/kubicorn**
...
Create, Manage, Image, and Scale Kubernetes infrastructure in the cloud.

Usage:
  kubicorn \[flags\]
  kubicorn \[command\]

Available Commands:
  adopt       Adopt a Kubernetes cluster into a Kubicorn state store
  apply       Apply a cluster resource to a cloud
  completion  Generate completion code for bash and zsh shells.
  create      Create a Kubicorn API model from a profile
  delete      Delete a Kubernetes cluster
  getconfig   Manage Kubernetes configuration
  help        Help about any command
  image       Take an image of a Kubernetes cluster
  list        List available states
  version     Verify Kubicorn version

Flags:
  -C, --color         Toggle colorized logs (default true)
  -f, --fab           Toggle colorized logs
  -h, --help          help for kubicorn
  -v, --verbose int   Log level (default 3)

Use "kubicorn \[command\] --help" for more information about a command.

Once you have the `kubicorn` command installed, you can create the cluster resources by selecting a _profile_ and verifying whether the resources are properly defined:

$ **kubicorn create --name k8scb --profile aws**
2017-08-14T05:18:24Z \[✔\]  Selected \[fs\] state store
2017-08-14T05:18:24Z \[✿\]  The state \[./\_state/k8scb/cluster.yaml\] has been...

$ **cat \_state/k8scb/cluster.yaml**
SSH:
  Identifier: ""
  metadata:
    creationTimestamp: null
  publicKeyPath: ~/.ssh/id\_rsa.pub
  user: ubuntu
cloud: amazon
kubernetesAPI:
  metadata:
    creationTimestamp: null
  port: "443"
location: us-west-2
...

Note

The default resource profile we’re using assumes you have a key pair in _~/.ssh_ named `id_rsa` (private key) and `id_rsa.pub` (public key). If this is not the case, you might want to change this. Also, note that the default region used is Oregon, `us-west-2`.

To continue, you need to have an AWS Identity and Access Management (IAM) user with the following permissions available: `AmazonEC2FullAccess`, `AutoScalingFullAccess`, and `AmazonVPCFullAccess`. If you don’t have such an IAM user, now is a good time to create one.\[[2](#_footnotedef_2 "View footnote.")\]

One last thing you need to do for `kubicorn` to work is set the credentials of the IAM user you’re using (see previous step) as environment variables, as follows:

$ **export AWS\_ACCESS\_KEY\_ID=\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\***
$ **export AWS\_SECRET\_ACCESS\_KEY=\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\***

Now you’re in a position to create the cluster, based on the resource definitions above as well as the AWS access you provided:

$ **kubicorn apply --name k8scb**
2017-08-14T05:45:04Z \[✔\]  Selected \[fs\] state store
2017-08-14T05:45:04Z \[✔\]  Loaded cluster: k8scb
2017-08-14T05:45:04Z \[✔\]  Init Cluster
2017-08-14T05:45:04Z \[✔\]  Query existing resources
2017-08-14T05:45:04Z \[✔\]  Resolving expected resources
2017-08-14T05:45:04Z \[✔\]  Reconciling
2017-08-14T05:45:07Z \[✔\]  Created KeyPair \[k8scb\]
2017-08-14T05:45:08Z \[✔\]  Created VPC \[vpc-7116a317\]
2017-08-14T05:45:09Z \[✔\]  Created Internet Gateway \[igw-e88c148f\]
2017-08-14T05:45:09Z \[✔\]  Attaching Internet Gateway \[igw-e88c148f\] to VPC ...
2017-08-14T05:45:10Z \[✔\]  Created Security Group \[sg-11dba36b\]
2017-08-14T05:45:11Z \[✔\]  Created Subnet \[subnet-50c0d919\]
2017-08-14T05:45:11Z \[✔\]  Created Route Table \[rtb-8fd9dae9\]
2017-08-14T05:45:11Z \[✔\]  Mapping route table \[rtb-8fd9dae9\] to internet gate...
2017-08-14T05:45:12Z \[✔\]  Associated route table \[rtb-8fd9dae9\] to subnet ...
2017-08-14T05:45:15Z \[✔\]  Created Launch Configuration \[k8scb.master\]
2017-08-14T05:45:16Z \[✔\]  Created Asg \[k8scb.master\]
2017-08-14T05:45:16Z \[✔\]  Created Security Group \[sg-e8dca492\]
2017-08-14T05:45:17Z \[✔\]  Created Subnet \[subnet-cccfd685\]
2017-08-14T05:45:17Z \[✔\]  Created Route Table \[rtb-76dcdf10\]
2017-08-14T05:45:18Z \[✔\]  Mapping route table \[rtb-76dcdf10\] to internet gate...
2017-08-14T05:45:19Z \[✔\]  Associated route table \[rtb-76dcdf10\] to subnet ...
2017-08-14T05:45:54Z \[✔\]  Found public IP for master: \[34.213.102.27\]
2017-08-14T05:45:58Z \[✔\]  Created Launch Configuration \[k8scb.node\]
2017-08-14T05:45:58Z \[✔\]  Created Asg \[k8scb.node\]
2017-08-14T05:45:59Z \[✔\]  Updating state store for cluster \[k8scb\]
2017-08-14T05:47:13Z \[✿\]  Wrote kubeconfig to \[/root/.kube/config\]
2017-08-14T05:47:14Z \[✿\]  The \[k8scb\] cluster has applied successfully!
2017-08-14T05:47:14Z \[✿\]  You can now \`kubectl get nodes\`
2017-08-14T05:47:14Z \[✿\]  You can SSH into your cluster ssh -i ~/.ssh/id\_rsa ...

Although you don’t see the beautiful coloring here, the last four lines of output are green and tell you that everything has been successfully set up. You can also verify this by visiting the Amazon EC2 console in a browser, as shown in [Screenshot of Amazon EC2 console, showing two nodes created by kubicorn](#azure-ec2-kubicorn).

![Screenshot of Amazon EC2 console, showing two nodes created by kubicorn](images/k8sc_1401.png)

Figure 1. Screenshot of Amazon EC2 console, showing two nodes created by kubicorn

Now, do as instructed in the last output line of the `kubicorn apply` command and `ssh` into the cluster:

$ **ssh -i ~/.ssh/id\_rsa ubuntu@34.213.102.27**
The authenticity of host '34.213.102.27 (34.213.102.27)' can't be established.
ECDSA key fingerprint is ed:89:6b:86:d9:f0:2e:3e:50:2a:d4:09:62:f6:70:bc.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '34.213.102.27' (ECDSA) to the list of known hosts.
Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-1020-aws x86\_64)

 \* Documentation:  https://help.ubuntu.com
 \* Management:     https://landscape.canonical.com
 \* Support:        https://ubuntu.com/advantage

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

75 packages can be updated.
32 updates are security updates.


To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo\_root" for details.

ubuntu@ip-10-0-0-52:~$ **kubectl get all -n kube-system**
NAME                                           READY     STATUS
po/calico-etcd-qr3f1                           1/1       Running
po/calico-node-9t472                           2/2       Running
po/calico-node-qlpp6                           2/2       Running
po/calico-policy-controller-1727037546-f152z   1/1       Running
po/etcd-ip-10-0-0-52                           1/1       Running
po/kube-apiserver-ip-10-0-0-52                 1/1       Running
po/kube-controller-manager-ip-10-0-0-52        1/1       Running
po/kube-dns-2425271678-zcfdd                   0/3       ContainerCreating
po/kube-proxy-3s2c0                            1/1       Running
po/kube-proxy-t10ck                            1/1       Running
po/kube-scheduler-ip-10-0-0-52                 1/1       Running

NAME              CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
svc/calico-etcd   10.96.232.136   <none>        6666/TCP        4m
svc/kube-dns      10.96.0.10      <none>        53/UDP,53/TCP   4m

NAME                              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
deploy/calico-policy-controller   1         1         1            1           4m
deploy/kube-dns                   1         1         1            0           4m

NAME                                     DESIRED   CURRENT   READY     AGE
rs/calico-policy-controller-1727037546   1         1         1         4m
rs/kube-dns-2425271678                   1         1         0         4m

When you’re done, tear down the Kubernetes cluster like so (note that this may take a couple of minutes):

$ **kubicorn delete --name k8scb**
2017-08-14T05:53:38Z \[✔\]  Selected \[fs\] state store
Destroying resources for cluster \[k8scb\]:
2017-08-14T05:53:41Z \[✔\]  Deleted ASG \[k8scb.node\]
...
2017-08-14T05:55:42Z \[✔\]  Deleted VPC \[vpc-7116a317\]

## Discussion

While `kubicorn` is a rather young project, it is fully functional, and you can also create clusters on [Azure](http://kubicorn.io/documentation/azure-walkthrough.html) and [Digital Ocean](http://kubicorn.io/documentation/do-walkthrough.html) with it.

It does require you to have Go installed as it doesn’t ship binaries (yet), but it’s very flexible in terms of configuration and also rather intuitive to handle, especially if you have an admin background.

## See Also

*   [Setting up Kubernetes in AWS](http://kubicorn.io/documentation/aws-walkthrough.html) in the `kubicorn` docs
    
*   Lachlan Evenson’s video walk-through ["Building a Kubernetes Cluster on Digital Ocean Using Kubicorn"](https://www.youtube.com/watch?v=XpxgSZ3dspE)