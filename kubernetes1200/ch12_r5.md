## Problem

You have a situation where a pod is either not starting up as expected or fails after some time.

## Solution

To systematically discover and fix the cause of the problem, enter an [OODA loop](https://en.wikipedia.org/wiki/OODA_loop):

1.  _Observe_. What do you see in the container logs? What events have occurred? How is the network connectivity?
    
2.  _Orient_. Formulate a set of plausible hypotheses—​stay as open-minded as possible and don’t jump to conclusions.
    
3.  _Decide_. Pick one of the hypotheses.
    
4.  _Act_. Test the hypothesis. If it’s confirmed, you’re done; otherwise, go back to step 1 and continue.
    

Let’s have a look at a concrete example where a pod fails. Create a manifest called _unhappy-pod.yaml_ with this content:

```
apiVersion:       extensions/v1beta1
kind:             Deployment
metadata:
  name:           unhappy
spec:
  replicas:       1
  template:
    metadata:
      labels:
        app:      nevermind
    spec:
      containers:
      - name:     shell
        image:    busybox
        command:
        - "sh"
        - "-c"
        - "echo I will just print something here and then exit"
```{{execute}}

Now when you launch that deployment and look at the pod it creates, you’ll see it’s unhappy:

$ **kubectl create -f unhappy-pod.yaml**
deployment "unhappy" created

$ **kubectl  get po**
NAME                       READY     STATUS             RESTARTS   AGE
unhappy-3626010456-4j251   0/1       CrashLoopBackOff   1          7s

$ **kubectl describe po/unhappy-3626010456-4j251**
Name:           unhappy-3626010456-4j251
Namespace:      default
Node:           minikube/192.168.99.100
Start Time:     Sat, 12 Aug 2017 17:02:37 +0100
Labels:         app=nevermind
                pod-template-hash=3626010456
Annotations:    kubernetes.io/created-by={"kind":"SerializedReference","apiVersion":
"v1","reference":{"kind":"ReplicaSet","namespace":"default","name":
"unhappy-3626010456","uid":
"a9368a97-7f77-11e7-b58a-080027390640"...
Status:         Running
IP:             172.17.0.13
Created By:     ReplicaSet/unhappy-3626010456
Controlled By:  ReplicaSet/unhappy-3626010456
...
Conditions:
  Type          Status
  Initialized   True
  Ready         False
  PodScheduled  True
Volumes:
  default-token-rlm2s:
    Type:       Secret (a volume populated by a Secret)
    SecretName: default-token-rlm2s
    Optional:   false
QoS Class:      BestEffort
Node-Selectors: <none>
Tolerations:    <none>
Events:
  FirstSeen   ...   Reason                  Message
  ---------   ...   ------                  -------
  25s         ...   Scheduled               Successfully assigned
                                            unhappy-3626010456-4j251 to minikube
  25s         ...   SuccessfulMountVolume   MountVolume.SetUp succeeded for
                                            volume "default-token-rlm2s"
  24s         ...   Pulling                 pulling image "busybox"
  22s         ...   Pulled                  Successfully pulled image "busybox"
  22s         ...   Created                 Created container
  22s         ...   Started                 Started container
  19s         ...   BackOff                 Back-off restarting failed container
  19s         ...   FailedSync              Error syncing pod

As you can see, Kubernetes considers this pod as not ready to serve traffic as it encountered an "error syncing pod."

Another way to observe this is using the Kubernetes dashboard to view the deployment ([Screenshot of deployment in error state](#unhappy-deployment-screenshot)), as well as the supervised replica set and the pod ([Screenshot of pod in error state](#unhappy-pod-events-screenshot)).

![Screen Shot Of Deployment In Error State](images/k8sc_1201.png)

Figure 1. Screenshot of deployment in error state

![Screen Shot Of Pod In Error State](images/k8sc_1202.png)

Figure 2. Screenshot of pod in error state

## Discussion

An issue, be it a pod failing or a node behaving strangely, can have many different causes. Here are some things you’ll want to check before suspecting software bugs:

*   Is the manifest correct? Check with the [Kubernetes JSON schema](https://github.com/garethr/kubernetes-json-schema).
    
*   Does the container run standalone, locally (that is, outside of Kubernetes)?
    
*   Can Kubernetes reach the container registry and actually pull the container image?
    
*   Can the nodes talk to each other?
    
*   Can the nodes reach the master?
    
*   Is DNS available in the cluster?
    
*   Are there sufficient resources available on the nodes?
    
*   Did you restrict the container’s [resource usage](https://hackernoon.com/container-resource-consumption-too-important-to-ignore-7484609a3bb7)?
    

## See Also

*   Kubernetes [Troubleshoot Applications documentation](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/)
    
*   [Application Introspection and Debugging](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application-introspection/)
    
*   [Debug Pods and Replication Controllers](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-pod-replication-controller/)
    
*   [Debug Services](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/)
    
*   [Troubleshoot Clusters](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/)