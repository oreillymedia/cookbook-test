## Problem

You need to carry out maintenance on a node—​for example, to apply a security patch or upgrade the operating system.

## Solution

Use the `kubectl drain` command. For example, to do maintenance on node `123-worker`:

$ **kubectl drain 123-worker**

When you are ready to put the node back into service, use `kubectl uncordon 123-worker`, which will make the node schedulable again.

## Discussion

What the `kubectl drain` command does is to first mark the specified node un-schedulable to prevent new pods from arriving (essentially a `kubectl cordon`). Then it evicts the pods if the API server supports [eviction](http://kubernetes.io/docs/admin/disruptions/). Otherwise, it will use normal `kubectl delete` to delete the pods. The Kubernetes docs have a concise sequence diagram of the steps, reproduced in [Node drain sequence diagram](#drain-node).

![Node drain sequence diagram](images/k8sc_1203.png)

Figure 3. Node drain sequence diagram

The kubectl drain command evicts or deletes all pods except mirror pods (which cannot be deleted through the API server). For pods supervised by a `DaemonSet`, `drain` will not proceed without using `--ignore-daemonsets`, and regardless it will not delete any `DaemonSet`\-managed pods—​those pods would be immediately replaced by the `DaemonSet` controller, which ignores unschedulable markings.

Warning

`drain` waits for graceful termination, so you should not operate on this node until the `kubectl drain` command has completed. Note that `kubectl drain $NODE --force` will also evict pods not managed by an RC, RS, job, `DaemonSet`, or `StatefulSet`.

## See Also

*   [Safely Drain a Node while Respecting Application SLOs](https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/)
    
*   The `kubectl` [reference docs](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#drain)